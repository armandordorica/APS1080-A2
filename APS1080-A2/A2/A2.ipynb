{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509d710e-b7ec-4513-96b9-b2abf3e903d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4c86024-5edb-4e77-8681-0ea5cf6dc2b5",
   "metadata": {},
   "source": [
    "1. Explain clearly why $V_{\\pi}$ is not useful in the MC development above?\n",
    "\n",
    "Because we don't have access to the transition dynamics (i.e. $p(s',r |s,a))$ of the environment. Rather, we need $Q_{\\pi}$\n",
    " so that we can derive the improved policy such that at state $s$, it choses action \n",
    " \n",
    "$$a = \\underset{a}{\\mathrm{argmax}} \\ Q_{\\pi_{k}}(s, a)$$\n",
    "\n",
    "\n",
    "2. The MC algorithm so far (ref: p 99), requires an infinite number of episodes for Eval to converge on Q_pi_k (step k). We can modify this algorithm to the practical variant where Eval is truncated (c.f., DynProg GPI). In this case:\n",
    "\n",
    "a. Will we obtain $Q_{\\pi_k}$ from eval?\n",
    "\n",
    "b. If not why are we able to truncate Eval? Explain clearly.\n",
    "\n",
    "c. Assuming ES (i.e., thorough sampling of the S x A space), and the above truncated Eval_trunc, is it possible to converge on a sub-optimal policy $\\pi_{c}$? Is this a stable fixed point of the GPI for MC? Explain clearly.\n",
    "\n",
    "3. Explain how you can synthesize a stochastic policy given what you know so far (you don't need to read ahead)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eac0574-02b9-4110-9098-2767832839d4",
   "metadata": {},
   "source": [
    "1. Explain clearly why V_pi is not useful in the MC development above?\n",
    "\n",
    " is a function that maps each state to a value given a specific policy \n",
    ". In the on-policy MC development, \n",
    " does not keep track of the optimal policy but rather also includes an \n",
    "-soft component to encourage random exploration. Therefore the \n",
    " is not useful since it does not accurate represent the value of the state. In fact, in off-policy MC, the policy to generate exploratory experiences is completely separated from the actual policy, which means \n",
    " does not indicate the actual value of the state. Instead, we shall track the state-action values \n",
    ".\n",
    "\n",
    "2. The MC algorithm so far (ref: p 99), requires an infinite number of episodes for Eval to converge on Q_pi_k (step k). We can modify this algorithm to the practical variant where Eval is truncated (c.f., DynProg GPI). In this case:\n",
    "\n",
    "a. Will we obtain Q_pi_k from eval?\n",
    "\n",
    "No. Since the evaluation is truncated, only an approximate solution will be obtained.\n",
    "\n",
    "b. If not why are we able to truncate Eval? Explain clearly.\n",
    "\n",
    "With the truncated evaluation we alternate more rapidly between policy evaluation and policy improvement. As more iterations are made we continously improve the policy and also the evaluation.\n",
    "\n",
    "c. Assuming ES (i.e., thorough sampling of the S x A space), and the above truncated Eval_trunc, is it possible to converge on a sub-optimal policy pi_c? Is this a stable fixed point of the GPI for MC? Explain clearly.\n",
    "\n",
    "It is not possible to converge on a sub-optimal policy since each iteration produces a non-inferior policy as compared to the previous iteration.\n",
    "\n",
    "3. Explain how you can synthesize a stochastic policy given what you know so far (you don't need to read ahead).\n",
    "\n",
    "One possible stochastic policy is to assign at least an \n",
    " probability for all state-action pairs such that all \n",
    " have a finite probability to be sampled, i.e. an \n",
    "-soft policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "907363bc-751b-4f1f-a913-2c9908a45023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://artifacts-prod-use1.pinadmin.com/artifactory/api/pypi/pinterest-python-pip-prod-virtual/simple/\n",
      "Collecting gymnasium\n",
      "  Downloading https://artifacts-prod-use1.pinadmin.com/artifactory/api/pypi/pinterest-python-pip-prod-virtual/packages/packages/60/82/3762ef4555791a729ae554e13c011efe5e8347d7eba9ea5ed245a8d1b234/gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m925.5/925.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /Users/aordorica/opt/anaconda3/lib/python3.9/site-packages (from gymnasium) (1.22.4)\n",
      "Collecting jax-jumpy>=1.0.0\n",
      "  Downloading https://artifacts-prod-use1.pinadmin.com/artifactory/api/pypi/pinterest-python-pip-prod-virtual/packages/packages/73/23/338caee543d80584916da20f018aeb017764509d964fd347b97f41f97baa/jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/aordorica/opt/anaconda3/lib/python3.9/site-packages (from gymnasium) (4.5.0)\n",
      "Collecting farama-notifications>=0.0.1\n",
      "  Downloading https://artifacts-prod-use1.pinadmin.com/artifactory/api/pypi/pinterest-python-pip-prod-virtual/packages/packages/05/2c/ffc08c54c05cdce6fbed2aeebc46348dbe180c6d2c541c7af7ba0aa5f5f8/Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /Users/aordorica/opt/anaconda3/lib/python3.9/site-packages (from gymnasium) (4.11.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/aordorica/opt/anaconda3/lib/python3.9/site-packages (from gymnasium) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/aordorica/opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gymnasium) (3.8.0)\n",
      "Installing collected packages: farama-notifications, jax-jumpy, gymnasium\n",
      "Successfully installed farama-notifications-0.0.4 gymnasium-0.28.1 jax-jumpy-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cf8be13-6880-4ce1-b128-c77097a311df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: gym[classic_control]\n"
     ]
    }
   ],
   "source": [
    "!pip install gym[classic_control]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50107908-91f5-44e5-95a3-50fdddd35701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "133c047e-e55c-4257-8bae-ddc10379d9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e1af5ca-e49c-48ee-b912-76b6f6b8e21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1', render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba70d478-f2ae-4cd0-9bc1-d197d3a3c95f",
   "metadata": {},
   "outputs": [
    {
     "ename": "DependencyNotInstalled",
     "evalue": "pygame is not installed, run `pip install gym[classic_control]`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gym/envs/classic_control/cartpole.py:219\u001b[0m, in \u001b[0;36mCartPoleEnv.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpygame\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpygame\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gfxdraw\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pygame'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gym/wrappers/time_limit.py:68\u001b[0m, in \u001b[0;36mTimeLimit.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m\"\"\"Resets the environment with :param:`**kwargs` and sets the number of steps elapsed to zero.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    The reset environment\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gym/wrappers/order_enforcing.py:42\u001b[0m, in \u001b[0;36mOrderEnforcing.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"Resets the environment with `kwargs`.\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gym/wrappers/env_checker.py:45\u001b[0m, in \u001b[0;36mPassiveEnvChecker.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_reset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_reset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menv_reset_passive_checker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:192\u001b[0m, in \u001b[0;36menv_reset_passive_checker\u001b[0;34m(env, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFuture gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m     )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# Checks the result of env.reset with kwargs\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    195\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(result)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    197\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gym/envs/classic_control/cartpole.py:206\u001b[0m, in \u001b[0;36mCartPoleEnv.reset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_beyond_terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32), {}\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gym/envs/classic_control/cartpole.py:222\u001b[0m, in \u001b[0;36mCartPoleEnv.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpygame\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gfxdraw\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DependencyNotInstalled(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpygame is not installed, run `pip install gym[classic_control]`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m     )\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscreen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     pygame\u001b[38;5;241m.\u001b[39minit()\n",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m: pygame is not installed, run `pip install gym[classic_control]`"
     ]
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4422ddf3-5b2c-4042-b2aa-ed4489b6dfc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
